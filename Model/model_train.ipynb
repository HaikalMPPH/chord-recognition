{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b320ea-6670-4c04-ac34-7ed84f364983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import joblib\n",
    "import gc\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27cda738-f042-4c78-9e07-fa0efe60f19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cens_C</th>\n",
       "      <th>Cens_Db</th>\n",
       "      <th>Cens_D</th>\n",
       "      <th>Cens_Eb</th>\n",
       "      <th>Cens_E</th>\n",
       "      <th>Cens_F</th>\n",
       "      <th>Cens_Gb</th>\n",
       "      <th>Cens_G</th>\n",
       "      <th>Cens_Ab</th>\n",
       "      <th>Cens_A</th>\n",
       "      <th>Cens_Bb</th>\n",
       "      <th>Cens_B</th>\n",
       "      <th>chord</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.458163</td>\n",
       "      <td>0.228498</td>\n",
       "      <td>0.335618</td>\n",
       "      <td>0.385245</td>\n",
       "      <td>0.280831</td>\n",
       "      <td>0.562060</td>\n",
       "      <td>0.101404</td>\n",
       "      <td>0.142517</td>\n",
       "      <td>0.211683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081103</td>\n",
       "      <td>0.007991</td>\n",
       "      <td>FMin7</td>\n",
       "      <td>../Datasets/1.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.456882</td>\n",
       "      <td>0.228481</td>\n",
       "      <td>0.329903</td>\n",
       "      <td>0.386718</td>\n",
       "      <td>0.270461</td>\n",
       "      <td>0.563033</td>\n",
       "      <td>0.104248</td>\n",
       "      <td>0.142325</td>\n",
       "      <td>0.223759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096144</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>FMin7</td>\n",
       "      <td>../Datasets/1.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.454308</td>\n",
       "      <td>0.229081</td>\n",
       "      <td>0.324611</td>\n",
       "      <td>0.388377</td>\n",
       "      <td>0.260669</td>\n",
       "      <td>0.563478</td>\n",
       "      <td>0.107217</td>\n",
       "      <td>0.142526</td>\n",
       "      <td>0.235052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110957</td>\n",
       "      <td>0.009594</td>\n",
       "      <td>FMin7</td>\n",
       "      <td>../Datasets/1.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.450574</td>\n",
       "      <td>0.230340</td>\n",
       "      <td>0.319815</td>\n",
       "      <td>0.390179</td>\n",
       "      <td>0.251621</td>\n",
       "      <td>0.563336</td>\n",
       "      <td>0.110333</td>\n",
       "      <td>0.143008</td>\n",
       "      <td>0.245606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125269</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>FMin7</td>\n",
       "      <td>../Datasets/1.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.445894</td>\n",
       "      <td>0.232287</td>\n",
       "      <td>0.315578</td>\n",
       "      <td>0.392097</td>\n",
       "      <td>0.243367</td>\n",
       "      <td>0.562581</td>\n",
       "      <td>0.113524</td>\n",
       "      <td>0.143594</td>\n",
       "      <td>0.255459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138864</td>\n",
       "      <td>0.010856</td>\n",
       "      <td>FMin7</td>\n",
       "      <td>../Datasets/1.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.207725</td>\n",
       "      <td>0.076254</td>\n",
       "      <td>0.397630</td>\n",
       "      <td>0.012440</td>\n",
       "      <td>0.081124</td>\n",
       "      <td>0.025550</td>\n",
       "      <td>0.113143</td>\n",
       "      <td>0.602074</td>\n",
       "      <td>0.253705</td>\n",
       "      <td>0.415162</td>\n",
       "      <td>0.012520</td>\n",
       "      <td>0.416366</td>\n",
       "      <td>AMin7</td>\n",
       "      <td>../Datasets/9.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.200846</td>\n",
       "      <td>0.072857</td>\n",
       "      <td>0.392787</td>\n",
       "      <td>0.013882</td>\n",
       "      <td>0.080756</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>0.115661</td>\n",
       "      <td>0.609691</td>\n",
       "      <td>0.257939</td>\n",
       "      <td>0.416193</td>\n",
       "      <td>0.013882</td>\n",
       "      <td>0.409283</td>\n",
       "      <td>AMin7</td>\n",
       "      <td>../Datasets/9.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.194574</td>\n",
       "      <td>0.068975</td>\n",
       "      <td>0.387773</td>\n",
       "      <td>0.015407</td>\n",
       "      <td>0.080133</td>\n",
       "      <td>0.031256</td>\n",
       "      <td>0.117944</td>\n",
       "      <td>0.616832</td>\n",
       "      <td>0.261322</td>\n",
       "      <td>0.417602</td>\n",
       "      <td>0.015407</td>\n",
       "      <td>0.402578</td>\n",
       "      <td>AMin7</td>\n",
       "      <td>../Datasets/9.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.188929</td>\n",
       "      <td>0.064633</td>\n",
       "      <td>0.382609</td>\n",
       "      <td>0.017022</td>\n",
       "      <td>0.079286</td>\n",
       "      <td>0.034334</td>\n",
       "      <td>0.119918</td>\n",
       "      <td>0.623479</td>\n",
       "      <td>0.263771</td>\n",
       "      <td>0.419261</td>\n",
       "      <td>0.017022</td>\n",
       "      <td>0.396526</td>\n",
       "      <td>AMin7</td>\n",
       "      <td>../Datasets/9.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.183925</td>\n",
       "      <td>0.059857</td>\n",
       "      <td>0.377302</td>\n",
       "      <td>0.018739</td>\n",
       "      <td>0.078254</td>\n",
       "      <td>0.037583</td>\n",
       "      <td>0.121490</td>\n",
       "      <td>0.629592</td>\n",
       "      <td>0.265280</td>\n",
       "      <td>0.421086</td>\n",
       "      <td>0.018739</td>\n",
       "      <td>0.391356</td>\n",
       "      <td>AMin7</td>\n",
       "      <td>../Datasets/9.mp3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399900 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cens_C   Cens_Db    Cens_D   Cens_Eb    Cens_E    Cens_F   Cens_Gb  \\\n",
       "0    0.458163  0.228498  0.335618  0.385245  0.280831  0.562060  0.101404   \n",
       "1    0.456882  0.228481  0.329903  0.386718  0.270461  0.563033  0.104248   \n",
       "2    0.454308  0.229081  0.324611  0.388377  0.260669  0.563478  0.107217   \n",
       "3    0.450574  0.230340  0.319815  0.390179  0.251621  0.563336  0.110333   \n",
       "4    0.445894  0.232287  0.315578  0.392097  0.243367  0.562581  0.113524   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "108  0.207725  0.076254  0.397630  0.012440  0.081124  0.025550  0.113143   \n",
       "109  0.200846  0.072857  0.392787  0.013882  0.080756  0.028333  0.115661   \n",
       "110  0.194574  0.068975  0.387773  0.015407  0.080133  0.031256  0.117944   \n",
       "111  0.188929  0.064633  0.382609  0.017022  0.079286  0.034334  0.119918   \n",
       "112  0.183925  0.059857  0.377302  0.018739  0.078254  0.037583  0.121490   \n",
       "\n",
       "       Cens_G   Cens_Ab    Cens_A   Cens_Bb    Cens_B  chord  \\\n",
       "0    0.142517  0.211683  0.000000  0.081103  0.007991  FMin7   \n",
       "1    0.142325  0.223759  0.000000  0.096144  0.008832  FMin7   \n",
       "2    0.142526  0.235052  0.000000  0.110957  0.009594  FMin7   \n",
       "3    0.143008  0.245606  0.000000  0.125269  0.010269  FMin7   \n",
       "4    0.143594  0.255459  0.000000  0.138864  0.010856  FMin7   \n",
       "..        ...       ...       ...       ...       ...    ...   \n",
       "108  0.602074  0.253705  0.415162  0.012520  0.416366  AMin7   \n",
       "109  0.609691  0.257939  0.416193  0.013882  0.409283  AMin7   \n",
       "110  0.616832  0.261322  0.417602  0.015407  0.402578  AMin7   \n",
       "111  0.623479  0.263771  0.419261  0.017022  0.396526  AMin7   \n",
       "112  0.629592  0.265280  0.421086  0.018739  0.391356  AMin7   \n",
       "\n",
       "              filename  \n",
       "0    ../Datasets/1.mp3  \n",
       "1    ../Datasets/1.mp3  \n",
       "2    ../Datasets/1.mp3  \n",
       "3    ../Datasets/1.mp3  \n",
       "4    ../Datasets/1.mp3  \n",
       "..                 ...  \n",
       "108  ../Datasets/9.mp3  \n",
       "109  ../Datasets/9.mp3  \n",
       "110  ../Datasets/9.mp3  \n",
       "111  ../Datasets/9.mp3  \n",
       "112  ../Datasets/9.mp3  \n",
       "\n",
       "[399900 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_hdf(\"./dataset.h5\", key=\"df\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11de6ab8-2a8e-41a7-800f-0d147241abdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_file = df[\"filename\"].unique()\n",
    "train_file, test_file = sk.model_selection.train_test_split(\n",
    "    unique_file,\n",
    "    random_state=42,\n",
    "    # test_size=0.1,\n",
    "    test_size=0.2,\n",
    ")\n",
    "# train_file, val_file = sk.model_selection.train_test_split(\n",
    "#     train_file,\n",
    "#     random_state=42,\n",
    "#     test_size=0.1,\n",
    "# )\n",
    "\n",
    "df_train = df[df[\"filename\"].isin(train_file)]\n",
    "# df_val = df[df[\"filename\"].isin(val_file)]\n",
    "df_test = df[df[\"filename\"].isin(test_file)]\n",
    "\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47a8cc95-d409-4481-9c95-79870dd3dfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chords\n",
      "\n",
      "## TRAIN ##\n",
      " chord\n",
      "DMaj7     12277\n",
      "GMaj7     11858\n",
      "AMaj7     11804\n",
      "EMaj7     11803\n",
      "AbMaj7    11793\n",
      "BbMaj7    11765\n",
      "CMin7     11718\n",
      "EbMaj7    11690\n",
      "BMaj7     11616\n",
      "GbMaj7    11557\n",
      "FMin7     11496\n",
      "AbMin7    11444\n",
      "CMaj7     11420\n",
      "DbMaj7    11374\n",
      "FMaj7     11368\n",
      "EMin7     11323\n",
      "GbMin7    11210\n",
      "DbMin7    11114\n",
      "DMin7     10945\n",
      "BbMin7    10941\n",
      "GMin7     10869\n",
      "AMin7     10850\n",
      "EbMin7    10765\n",
      "BMin7     10700\n",
      "G7         3035\n",
      "Bb7        2928\n",
      "C7         2922\n",
      "B7         2798\n",
      "Ab7        2762\n",
      "Db7        2756\n",
      "D7         2749\n",
      "A7         2734\n",
      "Eb7        2732\n",
      "Gb7        2709\n",
      "E7         2695\n",
      "F7         2680\n",
      "Name: count, dtype: int64\n",
      "\n",
      "## TEST ##\n",
      " chord\n",
      "EMin7     4380\n",
      "DbMin7    4312\n",
      "AbMin7    4306\n",
      "GbMin7    4302\n",
      "BMin7     4276\n",
      "AMin7     4180\n",
      "CMin7     4151\n",
      "FMin7     4102\n",
      "EbMin7    4031\n",
      "GMin7     4016\n",
      "BbMin7    4013\n",
      "DMin7     4006\n",
      "GMaj7     3446\n",
      "AMaj7     3407\n",
      "CMaj7     3239\n",
      "DMaj7     3187\n",
      "EMaj7     3116\n",
      "GbMaj7    3102\n",
      "EbMaj7    3097\n",
      "BbMaj7    3097\n",
      "DbMaj7    3094\n",
      "FMaj7     3076\n",
      "AbMaj7    3076\n",
      "BMaj7     3038\n",
      "B7         460\n",
      "C7         399\n",
      "Db7        394\n",
      "Ab7        386\n",
      "Bb7        383\n",
      "F7         382\n",
      "G7         379\n",
      "Eb7        379\n",
      "D7         372\n",
      "E7         372\n",
      "Gb7        372\n",
      "A7         372\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Chords\")\n",
    "print(\"\\n## TRAIN ##\\n\", df_train[\"chord\"].value_counts())\n",
    "# print(\"\\n## VAL ##\", df_val[\"chord\"].value_counts())\n",
    "print(\"\\n## TEST ##\\n\", df_test[\"chord\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddd00989-e358-43da-a693-754bd33bdc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./encoder.xz']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = df[\"chord\"]\n",
    "# X = df.drop(columns=\"chord\")\n",
    "# encoder = sk.preprocessing.LabelEncoder()\n",
    "# y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# joblib.dump(encoder, \"./encoder.xz\")\n",
    "\n",
    "def get_Xy(df: pd.DataFrame):\n",
    "    return df.drop([\"chord\", \"filename\"], axis=1), df[\"chord\"]\n",
    "\n",
    "X_train, y_train = get_Xy(df_train)\n",
    "# X_val, y_val = get_Xy(df_val)\n",
    "X_test, y_test = get_Xy(df_test)\n",
    "\n",
    "encoder = sk.preprocessing.LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "# y_val_encoded = encoder.transform(y_val)\n",
    "y_test_encoded = encoder.transform(y_test)\n",
    "\n",
    "joblib.dump(encoder, \"./encoder.xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b3d797b-bcb5-47fe-8e9e-c885d87a278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEQUENCE_LEN = 20 # 0.1 * 20.0 = 2 sec of sequence data\n",
    "\n",
    "# def make_seq(X, y_encoded):\n",
    "#     X_seq, y_encoded_seq = None, None\n",
    "#     X_seq_list = []\n",
    "#     y_encoded_seq_list = []\n",
    "#     for i in range(len(X) - SEQUENCE_LEN + 1):\n",
    "#         X_seq_list.append(X.values[i : i + SEQUENCE_LEN, :].flatten())\n",
    "#         y_encoded_seq_list.append(y_encoded[i + SEQUENCE_LEN - 1])\n",
    "    \n",
    "#     return np.array(X_seq_list), np.array(y_encoded_seq_list)\n",
    "\n",
    "# X_train, y_train_encoded = make_seq(X_train, y_train_encoded)\n",
    "# # X_val, y_val_encoded = make_seq(X_val, y_val_encoded)\n",
    "# X_test, y_test_encoded = make_seq(X_test, y_test_encoded)\n",
    "\n",
    "# print(\"TRAIN\")\n",
    "# print(\"X sequence shape: \", X_train.shape)\n",
    "# print(\"y sequence shape: \", y_train_encoded.shape)\n",
    "\n",
    "# # print(\"\\nVAL\")\n",
    "# # print(\"X sequence shape: \", X_val.shape)\n",
    "# # print(\"y sequence shape: \", y_val_encoded.shape)\n",
    "\n",
    "# print(\"\\nTEST\")\n",
    "# print(\"X sequence shape: \", X_test.shape)\n",
    "# print(\"y sequence shape: \", y_test_encoded.shape)\n",
    "\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134466c5-f3f9-4913-b86f-f9e858ada7df",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89151c52-93fb-4b3d-b758-c7657b74ca04",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e4f3703-6590-4d60-a952-d086310687f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ":::: SVM SEQ 5 ::::\n",
      "Training duration: 1127.2085177898407sec\n",
      "accuracy: 59.50202813497886%\n",
      "Testing duration: 1285.8626244068146sec\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A7       0.25      0.57      0.35       372\n",
      "       AMaj7       0.58      0.54      0.56      3407\n",
      "       AMin7       0.64      0.60      0.62      4180\n",
      "         Ab7       0.24      0.59      0.34       386\n",
      "      AbMaj7       0.57      0.58      0.57      3076\n",
      "      AbMin7       0.66      0.61      0.64      4306\n",
      "          B7       0.40      0.62      0.49       460\n",
      "       BMaj7       0.56      0.52      0.54      3038\n",
      "       BMin7       0.65      0.61      0.63      4276\n",
      "         Bb7       0.36      0.59      0.45       383\n",
      "      BbMaj7       0.60      0.56      0.58      3097\n",
      "      BbMin7       0.63      0.57      0.60      4013\n",
      "          C7       0.33      0.63      0.44       399\n",
      "       CMaj7       0.57      0.56      0.57      3235\n",
      "       CMin7       0.65      0.65      0.65      4151\n",
      "          D7       0.27      0.55      0.37       372\n",
      "       DMaj7       0.55      0.50      0.52      3187\n",
      "       DMin7       0.64      0.67      0.66      4006\n",
      "         Db7       0.29      0.62      0.39       394\n",
      "      DbMaj7       0.54      0.53      0.53      3094\n",
      "      DbMin7       0.63      0.66      0.64      4312\n",
      "          E7       0.35      0.60      0.45       372\n",
      "       EMaj7       0.58      0.52      0.55      3116\n",
      "       EMin7       0.67      0.66      0.67      4380\n",
      "         Eb7       0.30      0.52      0.38       379\n",
      "      EbMaj7       0.58      0.53      0.55      3097\n",
      "      EbMin7       0.67      0.69      0.68      4031\n",
      "          F7       0.31      0.59      0.40       382\n",
      "       FMaj7       0.56      0.51      0.53      3076\n",
      "       FMin7       0.67      0.61      0.64      4102\n",
      "          G7       0.40      0.64      0.49       379\n",
      "       GMaj7       0.59      0.59      0.59      3446\n",
      "       GMin7       0.70      0.64      0.67      4016\n",
      "         Gb7       0.33      0.58      0.42       372\n",
      "      GbMaj7       0.63      0.57      0.60      3102\n",
      "      GbMin7       0.70      0.66      0.68      4302\n",
      "\n",
      "    accuracy                           0.60     92696\n",
      "   macro avg       0.52      0.59      0.54     92696\n",
      "weighted avg       0.61      0.60      0.60     92696\n",
      "\n",
      "\n",
      ":::: SVM SEQ 10 ::::\n",
      "Training duration: 859.1983661651611sec\n",
      "accuracy: 59.59262495819443%\n",
      "Testing duration: 1450.1618337631226sec\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A7       0.30      0.59      0.40       372\n",
      "       AMaj7       0.59      0.54      0.56      3407\n",
      "       AMin7       0.63      0.61      0.62      4180\n",
      "         Ab7       0.25      0.59      0.35       386\n",
      "      AbMaj7       0.56      0.58      0.57      3076\n",
      "      AbMin7       0.66      0.61      0.64      4306\n",
      "          B7       0.45      0.61      0.52       460\n",
      "       BMaj7       0.56      0.54      0.55      3038\n",
      "       BMin7       0.65      0.62      0.64      4276\n",
      "         Bb7       0.40      0.60      0.48       383\n",
      "      BbMaj7       0.59      0.55      0.57      3097\n",
      "      BbMin7       0.63      0.58      0.60      4013\n",
      "          C7       0.37      0.59      0.46       399\n",
      "       CMaj7       0.55      0.55      0.55      3230\n",
      "       CMin7       0.64      0.65      0.65      4151\n",
      "          D7       0.31      0.56      0.40       372\n",
      "       DMaj7       0.55      0.49      0.52      3187\n",
      "       DMin7       0.63      0.67      0.65      4006\n",
      "         Db7       0.33      0.58      0.42       394\n",
      "      DbMaj7       0.53      0.52      0.53      3094\n",
      "      DbMin7       0.62      0.66      0.64      4312\n",
      "          E7       0.41      0.61      0.49       372\n",
      "       EMaj7       0.57      0.52      0.55      3116\n",
      "       EMin7       0.66      0.66      0.66      4380\n",
      "         Eb7       0.32      0.50      0.39       379\n",
      "      EbMaj7       0.58      0.51      0.54      3097\n",
      "      EbMin7       0.67      0.69      0.68      4031\n",
      "          F7       0.37      0.57      0.45       382\n",
      "       FMaj7       0.57      0.51      0.54      3076\n",
      "       FMin7       0.67      0.62      0.65      4102\n",
      "          G7       0.45      0.63      0.52       379\n",
      "       GMaj7       0.58      0.58      0.58      3446\n",
      "       GMin7       0.68      0.65      0.66      4016\n",
      "         Gb7       0.35      0.58      0.44       372\n",
      "      GbMaj7       0.63      0.58      0.60      3102\n",
      "      GbMin7       0.69      0.66      0.68      4302\n",
      "\n",
      "    accuracy                           0.60     92691\n",
      "   macro avg       0.53      0.59      0.55     92691\n",
      "weighted avg       0.60      0.60      0.60     92691\n",
      "\n",
      "\n",
      ":::: SVM SEQ 20 ::::\n",
      "Training duration: 1228.1079268455505sec\n",
      "accuracy: 59.18904629859411%\n",
      "Testing duration: 2254.2185337543488sec\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A7       0.28      0.54      0.36       372\n",
      "       AMaj7       0.58      0.51      0.54      3407\n",
      "       AMin7       0.62      0.62      0.62      4180\n",
      "         Ab7       0.24      0.57      0.33       386\n",
      "      AbMaj7       0.55      0.53      0.54      3076\n",
      "      AbMin7       0.64      0.63      0.63      4306\n",
      "          B7       0.39      0.61      0.48       460\n",
      "       BMaj7       0.54      0.50      0.52      3038\n",
      "       BMin7       0.63      0.66      0.65      4276\n",
      "         Bb7       0.37      0.62      0.46       383\n",
      "      BbMaj7       0.58      0.52      0.55      3097\n",
      "      BbMin7       0.62      0.59      0.61      4013\n",
      "          C7       0.35      0.56      0.43       399\n",
      "       CMaj7       0.56      0.54      0.55      3220\n",
      "       CMin7       0.63      0.66      0.64      4151\n",
      "          D7       0.35      0.61      0.45       372\n",
      "       DMaj7       0.59      0.48      0.53      3187\n",
      "       DMin7       0.62      0.68      0.65      4006\n",
      "         Db7       0.30      0.54      0.39       394\n",
      "      DbMaj7       0.54      0.49      0.51      3094\n",
      "      DbMin7       0.62      0.67      0.64      4312\n",
      "          E7       0.41      0.60      0.48       372\n",
      "       EMaj7       0.58      0.50      0.54      3116\n",
      "       EMin7       0.64      0.67      0.65      4380\n",
      "         Eb7       0.40      0.53      0.45       379\n",
      "      EbMaj7       0.58      0.49      0.53      3097\n",
      "      EbMin7       0.64      0.72      0.68      4031\n",
      "          F7       0.40      0.54      0.46       382\n",
      "       FMaj7       0.60      0.51      0.55      3076\n",
      "       FMin7       0.66      0.64      0.65      4102\n",
      "          G7       0.48      0.67      0.56       379\n",
      "       GMaj7       0.58      0.56      0.57      3446\n",
      "       GMin7       0.67      0.66      0.66      4016\n",
      "         Gb7       0.38      0.56      0.45       372\n",
      "      GbMaj7       0.62      0.54      0.58      3102\n",
      "      GbMin7       0.67      0.65      0.66      4302\n",
      "\n",
      "    accuracy                           0.59     92681\n",
      "   macro avg       0.53      0.58      0.54     92681\n",
      "weighted avg       0.60      0.59      0.59     92681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq_lens = [5, 10, 20]\n",
    "\n",
    "def make_seq(X, y_encoded, seq_len):\n",
    "    X_seq, y_encoded_seq = None, None\n",
    "    X_seq_list = []\n",
    "    y_encoded_seq_list = []\n",
    "    # for i in range(len(X) - SEQUENCE_LEN + 1):\n",
    "    #     X_seq_list.append(X.values[i : i + SEQUENCE_LEN, :].flatten())\n",
    "    #     y_encoded_seq_list.append(y_encoded[i + SEQUENCE_LEN - 1])\n",
    "    for i in range(len(X) - seq_len + 1):\n",
    "        X_seq_list.append(X.values[i : i + seq_len, :].flatten())\n",
    "        y_encoded_seq_list.append(y_encoded[i + seq_len - 1])\n",
    "    \n",
    "    return np.array(X_seq_list), np.array(y_encoded_seq_list)\n",
    "\n",
    "for seq_len in seq_lens: \n",
    "    X_train_seq, y_train_encoded_seq = make_seq(X_train, y_train_encoded, seq_len)\n",
    "    # X_val, y_val_encoded = make_seq(X_val, y_val_encoded)\n",
    "    X_test_seq, y_test_encoded_seq = make_seq(X_test, y_test_encoded, seq_len)\n",
    "\n",
    "    print(f'\\n:::: SVM SEQ {seq_len} ::::')\n",
    "    model_svc = sk.svm.SVC(\n",
    "        # class_weight=class_weight_dict,\n",
    "        class_weight=\"balanced\",\n",
    "        # C=1000,\n",
    "        # gamma=0.001,\n",
    "        # verbose=1\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    model_svc.fit(\n",
    "        X_train_seq,\n",
    "        y_train_encoded_seq,\n",
    "    )\n",
    "    end = time.time()\n",
    "    print(f\"Training duration: {end - start}sec\")\n",
    "\n",
    "    start = time.time()\n",
    "    y_pred = model_svc.predict(X_test_seq)\n",
    "    print(f\"accuracy: {sk.metrics.accuracy_score(y_pred, y_test_encoded_seq) * 100}%\")\n",
    "    end = time.time()\n",
    "    print(f\"Testing duration: {end - start}sec\")\n",
    "    \n",
    "    print(\n",
    "        sk.metrics.classification_report(y_test_encoded_seq, y_pred, target_names=encoder.classes_)\n",
    "    )\n",
    "    \n",
    "    joblib.dump(model_svc, f\"./model_svm_seq_{seq_len}.xz\")\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe812f2e-a71f-4ce5-b6ca-b7a8ac3ce140",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# grid_search_svc.fit(X_train, y_train_encoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_venv",
   "language": "python",
   "name": "thesis_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
